{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and problem solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(r\"C:\\Users\\wh\\Desktop\\us_tax_data\\dateset.xlsx - consumption_data.csv\")\n",
    "df_tax_sel = pd.read_csv(r\"C:\\Users\\wh\\Desktop\\us_tax_data\\dateset.xlsx - consumption_data.csv\")\n",
    "df_cons = pd.read_csv(r\"C:\\Users\\wh\\Desktop\\us_tax_data\\dateset.xlsx - consumption_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning df_raw\n",
    "# dropping all completely empty raws\n",
    "df_raw_2 = df_raw.dropna(how='all')\n",
    "\n",
    "# resetting the index\n",
    "df_raw_2 = df_raw_2.reset_index(drop='True')\n",
    "df_raw_2.head(10)\n",
    "\n",
    "# getting rid of regions in State/Region column\n",
    "df_raw_2 = df_raw_2[df_raw_2[\"State/Region\"].str.contains(\"Region\") == False]\n",
    "df_raw_2 = df_raw_2.reset_index(drop='True')\n",
    "df_raw_2.head(10)\n",
    "\n",
    "# left joining df_raw and df_tax_sel\n",
    "merged = df_raw_2.merge(df_tax_sel, on='Tax Code', how='left', indicator=True)\n",
    "\n",
    "# deleting all rows which contain 'no' in include\n",
    "merged2 = merged[merged['Include?'] != 'no']\n",
    "merged2 = merged2.reset_index(drop='True')\n",
    "\n",
    "# checking whether there still are rows with 'Include?' == 'no'\n",
    "merged2[merged2['Include?']=='no'].count()\n",
    "merged2.head(10)\n",
    "\n",
    "# making population readable as int\n",
    "merged2['Population'] = merged2['Population'].str.extract('(\\d+)', expand=False)\n",
    "merged2['Population'] = merged2['Population'].replace(np.nan, '0', regex=True)\n",
    "merged2['Population'] = merged2['Population'].astype(int)\n",
    "merged2['Population'] = merged2['Population'].replace(0, np.nan, regex=True)\n",
    "merged2\n",
    "\n",
    "# removing all special characters in tax names\n",
    "merged2['Tax Name'] = merged2['Tax Name'].str.replace('_N/A_', '')\n",
    "merged2\n",
    "merged2['Tax Name'] = merged2['Tax Name'].str.replace('\\W', '')\n",
    "merged2['Tax Name'] = merged2['Tax Name'].str.replace('_', '')\n",
    "merged2['Tax Name'].unique()\n",
    "\n",
    "# adding whitespace after each capital letter\n",
    "tax_names = merged2['Tax Name']\n",
    "tax_names = tax_names.replace(np.nan, 'Empty', regex=True)\n",
    "for i in range(len(tax_names)):\n",
    "    tax_names[i] = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", tax_names[i])\n",
    "tax_names = tax_names.replace('Empty', np.nan, regex=True)\n",
    "tax_names.unique()\n",
    "merged2['Tax Name 2'] = tax_names\n",
    "# Still one name is wrong, there is a whitespace missing\n",
    "merged2['Tax Name 2'] = merged2['Tax Name 2'].str.replace('Corporationsin', 'Corporations in')\n",
    "merged2['Tax Name 2'].unique()\n",
    "\n",
    "# checking if the number of included taxes is correct\n",
    "print(df_tax_sel[df_tax_sel['Include?']=='yes'].count() == merged2['Tax Name 2'].nunique())\n",
    "\n",
    "# checking if the columns are in correct format\n",
    "merged2.dtypes\n",
    "\n",
    "# taxes collected needs to be int\n",
    "merged2['Taxes Collected'].unique()\n",
    "\n",
    "# 'X' needs to be removed\n",
    "merged2['Taxes Collected'] = merged2['Taxes Collected'].replace('X', '0', regex=True)\n",
    "merged2['Taxes Collected'] = merged2['Taxes Collected'].replace(np.nan, '0', regex=True)\n",
    "merged2['Taxes Collected'] = merged2['Taxes Collected'].astype(int)\n",
    "merged2['Taxes Collected'] = merged2['Taxes Collected'].replace(0, np.nan, regex=True)\n",
    "\n",
    "# checking the column types again\n",
    "merged2.dtypes\n",
    "\n",
    "### cleaning consumption data \n",
    "# taking only rows and columns that are needed\n",
    "df_cons\n",
    "df_cons2 = df_cons.iloc[1:, 1:]\n",
    "\n",
    "# setting first row as column names\n",
    "df_cons2 = df_cons2.rename(columns=df_cons2.iloc[0])\n",
    "df_cons2 = df_cons2.reset_index(drop = 'True')\n",
    "\n",
    "# getting rid of first row which is a duplicate of the column names\n",
    "df_cons2 = df_cons2.iloc[1:4]\n",
    "df_cons2 = df_cons2.reset_index()\n",
    "\n",
    "# deleting index column \n",
    "del df_cons2['index']\n",
    "\n",
    "# transposing data to join it after with merged2 df\n",
    "df_cons_t = df_cons2.transpose()\n",
    "\n",
    "# setting first row as column names\n",
    "df_cons_t = df_cons_t.rename(columns=df_cons_t.iloc[0])\n",
    "\n",
    "# Taking states out from index and adding as a seperate column\n",
    "df_cons_t['State'] = df_cons_t.index\n",
    "\n",
    "# taking everything except of the first row\n",
    "df_cons_t = df_cons_t.iloc[1:,:]\n",
    "df_cons_t = df_cons_t.reset_index(drop='True')\n",
    "df_cons_t['State'] = df_cons_t['State'].replace('United States total', 'United States', regex=True)\n",
    "df_cons_t['2018'] = df_cons_t['2018'].astype(int)\n",
    "df_cons_t['2019'] = df_cons_t['2019'].astype(int)\n",
    "df_cons_t['2020'] = df_cons_t['2020'].astype(int)\n",
    "df_cons_t.dtypes\n",
    "df_cons_t\n",
    "\n",
    "# correcting district of columbia to dc\n",
    "df_cons_t['State'] = df_cons_t['State'].replace('District of Columbia', 'DC', regex=True)\n",
    "\n",
    "# joining df_cons_t with merged2\n",
    "merged_all = merged2.merge(df_cons_t, left_on='State/Region',right_on ='State' ,how='left')\n",
    "merged_all = merged_all[merged_all[\"State/Region\"].str.contains(\"United States\") == False]\n",
    "merged_all.head(10)\n",
    "\n",
    "#creating a final df with columns needed to answer the questions and getting rid of United States in total\n",
    "final = merged_all[['State/Region', 'Taxes Collected', 'Population', 'Tax Name 2', 'Region']]\n",
    "final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution for Problem 1\n",
      "State/Region\n",
      "DC    21.914669\n",
      "dtype: float64\n",
      "Solution for Problem 2\n",
      "State/Region\n",
      "California    347066701.0\n",
      "New York      177020522.0\n",
      "Illinois       70675224.0\n",
      "Name: Taxes Collected, dtype: float64\n",
      "Solution for Problem 3\n",
      "Region\n",
      "Western South Region    18526820.0\n",
      "Name: Taxes Collected, dtype: float64\n",
      "Solution for Problem 4\n",
      "                 State/Region\n",
      "Change 2019/2020             \n",
      "1.24                    Idaho\n",
      "Solution for Problem 5\n",
      "                             2020  Population  avg_per_con\n",
      "Region                                                    \n",
      "New England Region         744663  14802967.0     0.050305\n",
      "Middle Atlantic Region    1978557  41269709.0     0.047942\n",
      "Pacific Region            2467638  53135362.0     0.046441\n",
      "Southern Atlantic Region  2752023  64641801.0     0.042573\n",
      "Mountain Region           1011715  24184624.0     0.041833\n",
      "Western Midwest Region     880031  21277130.0     0.041360\n",
      "Eastern Midwest Region    1927402  46878905.0     0.041114\n",
      "Western South Region      1579945  39929172.0     0.039569\n",
      "Eastern South Region       694480  19027451.0     0.036499\n"
     ]
    }
   ],
   "source": [
    "# 1.Determine state which has the highest amount of taxes per person.\n",
    "sum_taxes = final.groupby(by='State/Region')['Taxes Collected'].sum()\n",
    "pop = final.groupby(by='State/Region')['Population'].max()\n",
    "taxes_per_person = sum_taxes/pop\n",
    "print(\"Solution for Problem 1\")\n",
    "print(taxes_per_person.sort_values(ascending=False).head(1))\n",
    "\n",
    "# 2.Determine state with the third largest amount of collected taxes.\n",
    "taxes_collected = final.groupby(by='State/Region')['Taxes Collected'].sum().sort_values(ascending=False)\n",
    "print(\"Solution for Problem 2\")\n",
    "print(taxes_collected.head(3))\n",
    "\n",
    "# 3.Name region with the smallest value of sum of \"Individual Income Taxes\" and \"Income Taxes\".\n",
    "only_two_taxes = final[final['Tax Name 2'].isin(['Individual Income Taxes','Income Taxes'])]\n",
    "only_two_taxes_s = only_two_taxes.groupby(by='Region')['Taxes Collected'].sum().sort_values(ascending=True)\n",
    "print(\"Solution for Problem 3\")\n",
    "print(only_two_taxes_s.head(1))\n",
    "\n",
    "# 4.Calculate percent changes of personal consumption expenditures between 2018 and 2020 for each state and determine state and year with highest change (example: Florida 2018/2019)\n",
    "final_4 = merged_all[['State/Region', '2018', '2019', '2020']]\n",
    "final_5 = final_4.drop_duplicates()\n",
    "final_5 = final_5.reset_index(drop='True')\n",
    "# calculating the percentage change \n",
    "final_5['Change 2018/2019'] = round(((final_5['2019']-final_5['2018'])/final_5['2018']*100),2)\n",
    "final_5['Change 2019/2020'] = round(((final_5['2020']-final_5['2019'])/final_5['2019']*100),2)\n",
    "final_5 = final_5[['State/Region', 'Change 2018/2019', 'Change 2019/2020']]\n",
    "final_5[['State/Region', 'Change 2018/2019']].groupby(by='Change 2018/2019').max().sort_values(by = 'Change 2018/2019',ascending=False).head(1)\n",
    "print(\"Solution for Problem 4\")\n",
    "print(final_5[['State/Region', 'Change 2019/2020']].groupby(by='Change 2019/2020').max().sort_values(by = 'Change 2019/2020',ascending=False).head(1))\n",
    "\n",
    "\n",
    "# 5.Determine Region with the highest average Personal Consumption Expenditures per person in 2020\n",
    "# keep in mind to multiply by million (million of dollars consumption)\n",
    "final_6 = merged_all[['Region','2020', 'Population']]\n",
    "final_6 = final_6.dropna()\n",
    "final_6 = final_6.reset_index(drop='True')\n",
    "final_6 = final_6.groupby(by='Region').sum()\n",
    "final_6['avg_per_con'] = (final_6['2020']/final_6['Population'])\n",
    "print(\"Solution for Problem 5\")\n",
    "print(final_6.sort_values(by = 'avg_per_con',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting Data for Google Data Studio to visualise it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all.to_csv(r\"C:\\Users\\wh\\Desktop\\us_tax_data\\merged_all.csv\")\n",
    "\n",
    "df_cons_t_2=  df_cons_t.merge(merged2, left_on='State',right_on ='State/Region' ,how='left')\n",
    "df_cons_t_2 = df_cons_t_2[['2018', '2019', '2020', 'State', 'Region', 'Population']]\n",
    "df_cons_t_2 = df_cons_t_2.dropna()\n",
    "df_cons_t_2.to_csv(r\"C:\\Users\\wh\\Desktop\\us_tax_data\\consumption_over_time_2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can view the Dashboad via the link below\n",
    "\n",
    "https://lookerstudio.google.com/reporting/e7beec96-ea03-4353-a26d-304feb9bbee8\n",
    "\n",
    "This Dashboad wass built within 3 hours, therefore the Visualization could be done pettie, but I focused on visualising the insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('portfolio': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc3613dc7301877e1335a29a4e4d3285b22a0737ec6ffd846cf3499a3147d34f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
